{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models for TRECQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how the deep learning models work.  \n",
    "These files provides five baseline models, i.e. average pooling, RNN, CNN, RNNCNN, QA-LSTM/CNN+attention (Tan, 2015; state-of-art 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import sys,os\n",
    "\n",
    "import utils\n",
    "import csv\n",
    "\n",
    "import keras.activations as activations\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, TimeDistributed, BatchNormalization\n",
    "from keras.layers.merge import concatenate, add, multiply\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Lambda, Permute, RepeatVector\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    c = dict()\n",
    "    # embedding params\n",
    "    c['emb'] = 'Glove'\n",
    "    c['embdim'] = 300\n",
    "    c['inp_e_dropout'] = 1/2\n",
    "    c['flag'] = True\n",
    "\n",
    "    # training hyperparams\n",
    "    c['opt'] = 'adadelta'\n",
    "    c['batch_size'] = 160   \n",
    "    c['epochs'] = 16\n",
    "    c['patience'] = 3\n",
    "    \n",
    "    # sentences with word lengths below the 'pad' will be padded with 0.\n",
    "    c['pad'] = 60\n",
    "    \n",
    "    # rnn model       \n",
    "    c['rnn_dropout'] = 1/2     \n",
    "    c['l2reg'] = 1e-4\n",
    "                                              \n",
    "    c['rnnbidi'] = True                      \n",
    "    c['rnn'] = CuDNNLSTM\n",
    "    c['rnnbidi_mode'] = concatenate\n",
    "    c['rnnact'] = 'tanh'\n",
    "    c['rnninit'] = 'glorot_uniform'                      \n",
    "    c['sdim'] = 5\n",
    "\n",
    "    # cnn model\n",
    "    c['cnn_dropout'] = 1/2     \n",
    "    c['pool_layer'] = MaxPooling1D\n",
    "    c['cnnact'] = 'relu'\n",
    "    c['cnninit'] = 'glorot_uniform'\n",
    "    c['cdim'] = 2\n",
    "    c['pact'] = 'tanh'\n",
    "\n",
    "    # projection layer\n",
    "    c['proj'] = False\n",
    "    c['pdim'] = 1/2\n",
    "    c['p_layers'] = 1\n",
    "    c['p_dropout'] = 1/2\n",
    "    c['p_init'] = 'glorot_uniform'\n",
    "    \n",
    "    # attention model\n",
    "    c['adim'] = 1/2\n",
    "    c['cdim'] = 2\n",
    "    c['cfiltlen'] = 3\n",
    "\n",
    "    # mlp scoring function\n",
    "    c['Ddim'] = 2\n",
    "    \n",
    "    ps, h = utils.hash_params(c)\n",
    "\n",
    "    return c, ps, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = None\n",
    "emb = None\n",
    "vocab = None\n",
    "inp_tr = None\n",
    "inp_val = None\n",
    "inp_test = None\n",
    "y_val = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranknet(y_true, y_pred):\n",
    "    return K.mean(K.log(1. + K.exp(-(y_true * y_pred - (1-y_true) * y_pred))), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "Load TrecQA dataset (wang et al. 2007).  http://cs.stanford.edu/people/mengqiu/data/qg-emnlp07-data.tgz\n",
    "\n",
    "The format of the dataset is as follows.\n",
    "\n",
    "- question1, label, sentence1   \n",
    "- question1, label, sentence2   \n",
    "         \n",
    "         ...\n",
    "                                         \n",
    "- question2, label, sentence1  \n",
    "- question2, label, sentence2  \n",
    "          \n",
    "         ...\n",
    "          \n",
    "- questionN, label, sentenceM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(dsfile):\n",
    "    #load a dataset in the csv format;\n",
    "    q = [] # a set of questions\n",
    "    sents = [] # a set of sentences\n",
    "    labels = [] # a set of labels\n",
    "\n",
    "    with open(dsfile) as f:\n",
    "        c = csv.DictReader(f)\n",
    "        for l in c:\n",
    "            label = int(l['label'])\n",
    "            labels.append(label)\n",
    "            try:\n",
    "                qtext = l['qtext'].decode('utf8')\n",
    "                stext = l['atext'].decode('utf8')\n",
    "            except AttributeError:  # python3 has no .decode()\n",
    "                qtext = l['qtext']\n",
    "                stext = l['atext']\n",
    "            \n",
    "            q.append(qtext.split(' '))\n",
    "            sents.append(stext.split(' '))\n",
    "            \n",
    "    return (q, sents, labels)\n",
    "    \n",
    "def make_model_inputs(qi, si, f01, f10, q, sents, y):\n",
    "    inp = {'qi': qi, 'si': si, 'f01':f01, 'f10':f10, 'q':q, 'sents':sents, 'y':y} \n",
    "    \n",
    "    return inp\n",
    "\n",
    "def load_set(fname, vocab=None, iseval=False):\n",
    "    q, sents, y = load_data_from_file(fname)\n",
    "    if not iseval:\n",
    "        vocab = utils.Vocabulary(q + sents) \n",
    "    \n",
    "    pad = conf['pad']\n",
    "    \n",
    "    qi = vocab.vectorize(q, pad=pad)  \n",
    "    si = vocab.vectorize(sents, pad=pad)        \n",
    "    f01, f10 = utils.sentence_flags(q, sents, pad)  \n",
    "    \n",
    "    inp = make_model_inputs(qi, si, f01, f10, q, sents, y)\n",
    "    if iseval:\n",
    "        return (inp, y)\n",
    "    else:\n",
    "        return (inp, y, vocab)        \n",
    "    \n",
    "def load_data(trainf, valf, testf):\n",
    "    global vocab, inp_tr, inp_val, inp_test, y_train, y_val, y_test\n",
    "    inp_tr, y_train, vocab = load_set(trainf, iseval=False)\n",
    "    inp_val, y_val = load_set(valf, vocab=vocab, iseval=True)\n",
    "    inp_test, y_test = load_set(testf, vocab=vocab, iseval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding():\n",
    "    '''\n",
    "    Declare all inputs (vectorized sentences and NLP flags)\n",
    "    and generate outputs representing vector sequences with dropout applied.  \n",
    "    Returns the vector dimensionality.       \n",
    "    '''\n",
    "    pad = conf['pad']\n",
    "    dropout = conf['inp_e_dropout']\n",
    "    \n",
    "    # story selection\n",
    "    input_qi = Input(name='qi', shape=(pad,), dtype='int32')                          \n",
    "    input_si = Input(name='si', shape=(pad,), dtype='int32')                 \n",
    "    input_f01 = Input(name='f01', shape=(pad, utils.flagsdim))\n",
    "    input_f10 = Input(name='f10', shape=(pad, utils.flagsdim))         \n",
    "\n",
    "    if conf['flag']:\n",
    "        input_nodes = [input_qi, input_si, input_f01, input_f10]\n",
    "        N = emb.N + utils.flagsdim\n",
    "    else:\n",
    "        input_nodes = [input_qi, input_si]\n",
    "        N = emb.N\n",
    "\n",
    "    shared_embedding = Embedding(name='emb', input_dim=vocab.size(), input_length=pad,\n",
    "                                output_dim=emb.N, mask_zero=False,\n",
    "                                weights=[vocab.embmatrix(emb)], trainable=True)\n",
    "    if conf['flag']:\n",
    "        emb_qi = Dropout(dropout, noise_shape=(N,))(concatenate([shared_embedding(input_qi),\n",
    "            input_f01]))\n",
    "        emb_si = Dropout(dropout, noise_shape=(N,))(concatenate([shared_embedding(input_si),\n",
    "            input_f10]))\n",
    "    else:\n",
    "        emb_qi = Dropout(dropout, noise_shape=(N,))(shared_embedding(input_qi))\n",
    "        emb_si = Dropout(dropout, noise_shape=(N,))(shared_embedding(input_si))\n",
    "\n",
    "    emb_outputs = [emb_qi, emb_si]\n",
    "    \n",
    "    return N, input_nodes, emb_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Averaging model\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/avg.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_model(input_nodes, N, pfx=''):\n",
    "    shared_dense = Dense(int(N), activation='linear', name='wproj'+pfx)\n",
    "    qi_wproj = TimeDistributed(shared_dense)(input_nodes[0])\n",
    "    si_wproj = TimeDistributed(shared_dense)(input_nodes[1])\n",
    "    \n",
    "    qi_wproj = TimeDistributed(BatchNormalization())(qi_wproj)\n",
    "    si_wproj = TimeDistributed(BatchNormalization())(si_wproj)\n",
    "\n",
    "    qi_wproj = TimeDistributed(Activation('tanh'))(qi_wproj)\n",
    "    si_wproj = TimeDistributed(Activation('tanh'))(si_wproj)\n",
    "    \n",
    "    avg_layer = Lambda(name='bow'+pfx, function=lambda x: K.mean(x, axis=1), output_shape=lambda shape:(shape[0],) + shape[2:])\n",
    "    qi_avg = avg_layer(qi_wproj)\n",
    "    si_avg = avg_layer(si_wproj)\n",
    "\n",
    "    if conf['proj']:\n",
    "        qi_avg, si_avg = projection_layer([qi_avg, si_avg], int(N))\n",
    "\n",
    "    return [qi_avg, si_avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using projection layer, models can be getting deeper\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/projection.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projection_layer(inputs, input_size):\n",
    "    input0 = inputs[0]\n",
    "    input1 = inputs[1]\n",
    "    for p_i in range(conf['p_layers']):\n",
    "        shared_dense = Dense(name='pdeep%d'%(p_i), output_dim=int(input_size*conf['pdim']),\n",
    "                activation='linear', kernel_initializer=conf['p_init'], kernel_regularizer=l2(conf['l2reg']))\n",
    "        qi_proj = Activation(conf['pact'])(BatchNormalization()(shared_dense(input0)))\n",
    "        si_proj = Activation(conf['pact'])(BatchNormalization()(shared_dense(input1)))\n",
    "        input0 = qi_proj\n",
    "        input1 = si_proj\n",
    "        input_size = int(input_size * conf['pdim'])\n",
    "\n",
    "    dropout = conf['p_dropout']\n",
    "    qi_proj = Dropout(dropout, noise_shape=(input_size,))(qi_proj)\n",
    "    si_proj = Dropout(dropout, noise_shape=(input_size,))(si_proj)\n",
    "\n",
    "    return qi_proj, si_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RNN model\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/rnn.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(input_nodes, N, pfx=''):\n",
    "    qi_rnn, si_rnn, nc = rnn_input(N, pfx=pfx, dropout=conf['rnn_dropout'], sdim=conf['sdim'], \n",
    "                            rnnbidi_mode=conf['rnnbidi_mode'], rnn=conf['rnn'], rnnact=conf['rnnact'], \n",
    "                            rnninit=conf['rnninit'], inputs=input_nodes, return_sequence=False)\n",
    "\n",
    "    if conf['proj']:\n",
    "        qi_rnn, si_rnn = projection_layer([qi_rnn, si_rnn], nc)\n",
    "\n",
    "    return [qi_rnn, si_rnn]\n",
    "\n",
    "def rnn_input(N, dropout=3/4, sdim=2, rnn=GRU, rnnact='tanh', rnninit='glorot_uniform', rnnbidi_mode=add, \n",
    "              inputs=None, return_sequence=True, pfx=''):\n",
    "    if rnnbidi_mode == concatenate:\n",
    "        sdim /= 2\n",
    "    shared_rnn_f = rnn(int(N*sdim), kernel_initializer=rnninit, input_shape=(None, conf['pad'], N), \n",
    "                       return_sequences=False, name='rnnf'+pfx)\n",
    "    shared_rnn_b = rnn(int(N*sdim), kernel_initializer=rnninit, input_shape=(None, conf['pad'], N),\n",
    "                       return_sequences=False, go_backwards=True, name='rnnb'+pfx)\n",
    "    qi_rnn_f = shared_rnn_f(inputs[0])\n",
    "    si_rnn_f = shared_rnn_f(inputs[1])\n",
    "    \n",
    "    qi_rnn_b = shared_rnn_b(inputs[0])\n",
    "    si_rnn_b = shared_rnn_b(inputs[1])\n",
    "    \n",
    "    qi_rnn = Activation(rnnact)(BatchNormalization()(rnnbidi_mode([qi_rnn_f, qi_rnn_b])))\n",
    "    si_rnn = Activation(rnnact)(BatchNormalization()(rnnbidi_mode([si_rnn_f, si_rnn_b])))\n",
    "    \n",
    "    if rnnbidi_mode == concatenate:\n",
    "        sdim *= 2\n",
    "        \n",
    "    qi_rnn = Dropout(dropout, noise_shape=(int(N*sdim),))(qi_rnn)\n",
    "    si_rnn = Dropout(dropout, noise_shape=(int(N*sdim),))(si_rnn)\n",
    "    \n",
    "    return (qi_rnn, si_rnn, int(N*sdim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CNN model\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/cnn.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_nodes, N, pfx=''):\n",
    "    qi_cnn, si_cnn, nc = cnnsum_input(conf['pad'], dropout=conf['dropout'],\n",
    "                                l2reg=conf['l2reg'], cnninit=conf['cnninit'], cnnact=conf['cnnact'],\n",
    "                                input_dim=N, inputs=input_nodes)\n",
    "    if conf['proj']:\n",
    "        qi_cnn, si_cnn = projection_layer([qi_cnn, si_cnn], nc)\n",
    "\n",
    "    return [qi_cnn, si_cnn]\n",
    "\n",
    "def cnnsum_input(pad, dropout=3/4, l2reg=1e-4, cnninit='glorot_uniform', cnnact='relu',\n",
    "        cdim={1: 1/2, 2: 1/2, 3: 1/2, 4: 1/2, 5: 1/2, 6: 1/2, 7: 1/2}, inputs=None, input_dim=304, pfx=''):\n",
    "    qi_cnn_res_list = []\n",
    "    si_cnn_res_list = []\n",
    "    tot_len = 0\n",
    "    for fl, cd in cdim.items():\n",
    "        nb_filter = int(input_dim*cd)\n",
    "        shared_conv = Convolution1D(name=pfx+'conv%d'%(fl), input_shape=(None, conf['pad'], N),\n",
    "                    kernel_size=fl, filters=nb_filter, activation='linear',\n",
    "                    kernel_regularizer=l2(l2reg), kernel_initializer=cnninit)\n",
    "        qi_cnn_one = Activation(cnnact)(BatchNormalization()(shared_conv(inputs[0])))\n",
    "        si_cnn_one = Activation(cnnact)(BatchNormalization()(shared_conv(inputs[1])))\n",
    "        \n",
    "        pool = MaxPooling1D(pool_size=int(conf['pad']-fl+1), name=pfx+'pool%d'%(fl))\n",
    "        qi_pool_one = pool(qi_cnn_one)\n",
    "        si_pool_one = pool(si_cnn_one)\n",
    "\n",
    "        flatten = Flatten(name=pfx+'flatten%d'%(fl))\n",
    "        qi_out_one = flatten(qi_pool_one)\n",
    "        si_out_one = flatten(si_pool_one)\n",
    "\n",
    "        qi_cnn_res_list.append(qi_out_one)\n",
    "        si_cnn_res_list.append(si_out_one)\n",
    "    \n",
    "        tot_len += nb_filter\n",
    "\n",
    "    qi_cnn = Dropout(dropout, noise_shape=(tot_len,))(concatenate(qi_cnn_res_list))\n",
    "    si_cnn = Dropout(dropout, noise_shape=(tot_len,))(concatenate(si_cnn_res_list))\n",
    "\n",
    "    return (qi_cnn, si_cnn, tot_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RNNCNN model\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/rnncnn.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnncnn_model(input_nodes, N, pfx=''):\n",
    "    qi_rnncnn, si_rnncnn, nc = rnn_input(N, pfx=pfx, dropout=conf['rnn_dropout'], sdim=conf['sdim'], \n",
    "                            rnnbidi_mode=conf['rnnbidi_mode'], rnn=conf['rnn'], rnnact=conf['rnnact'], \n",
    "                            rnninit=conf['rnninit'], inputs=input_nodes, return_sequence=True)\n",
    "    \n",
    "    qi_rnncnn, si_rnncnn, nc = cnnsum_input(N, conf['pad'], \n",
    "                                l2reg=conf['l2reg'], cnninit=conf['cnninit'], cnnact=conf['cnnact'], input_dim=nc,\n",
    "                                inputs=[qi_rnn, si_rnn], cdim={1: 1/2, 2: 1/2, 3: 1/2, 4: 1/2, 5: 1/2},\n",
    "                                pfx='aggre_q'+pfx)\n",
    "\n",
    "    if conf['proj']:\n",
    "        qi_rnncnn, si_rnncnn = projection_layer([qi_rnncnn, si_rnncnn], nc) \n",
    "\n",
    "    return [qi_rnncnn, si_rnncnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. QA-LSTM/CNN model\n",
    "\n",
    "The model builds the embeddings of two sequences of tokens X, Y. The model encodes each token of X, Y using a bidirectional LSTM and calculates the sentence vector X by applying a convolution on the output token vectors of the bidirectional LSTM on the X side. Then the each token vector of Y are multiplied by a softmax weight, which is determined by X. \n",
    "\n",
    "$$m(t)=tanh(W_ah_y(t)+W_qX)$$\n",
    "$$o_t \\propto exp(w^t_{ms}m(t))$$\n",
    "$$h^\\prime_y(t)=h_y(t)o_t$$\n",
    "\n",
    "where \n",
    "- $h_y(t)$ is the t-th token vector on the Y side.\n",
    "- $h^\\prime_y(t)$ is the\n",
    "updated t-th token vector. \n",
    "- $W_a, W_q, w_{ms}$ are attention\n",
    "parameters\n",
    "\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/qa_lstmcnn.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_model(input_nodes, N, pfx=''):\n",
    "    qi_rnn, si_rnn, nc_rnn = rnn_input(N, pfx=pfx, dropout=conf['rnn_dropout'], sdim=conf['sdim'],\n",
    "                            rnnbidi_mode=conf['rnnbidi_mode'], rnn=conf['rnn'], rnnact=conf['rnnact'],\n",
    "                            rnninit=conf['rnninit'], inputs=input_nodes, return_sequence=True)\n",
    "\n",
    "    # calculate the sentence vector on X side using Convolutional Neural Networks\n",
    "    qi_aggreg, nc_cnn = aggregate(N, conf['pad'], l2reg=conf['l2reg'], cnninit=conf['cnninit'], \n",
    "                                  cnnact=conf['cnnact'], input_dim=nc_rnn, inputs=qi_rnn, \n",
    "                                  cdim={1: 1/2, 2: 1/2, 3: 1/2, 4: 1/2, 5: 1/2}, pfx='aggre_q'+pfx)\n",
    "\n",
    "    # re-embed X,Y in attention space\n",
    "    adim = int(N*conf['adim'])\n",
    "    shared_dense_q = Dense(adim, name='attn_proj_q'+pfx, kernel_regularizer=l2(conf['l2reg']), \n",
    "                           kernel_initializer=conf['p_init'])\n",
    "    qi_aggreg_attn = BatchNormalization()(shared_dense_q(qi_aggreg))\n",
    "\n",
    "\n",
    "    shared_dense_s = Dense(adim, name='attn_proj_s'+pfx, kernel_regularizer=l2(conf['l2reg']), \n",
    "                           kernel_initializer=conf['p_init'])\n",
    "    si_attn = TimeDistributed(shared_dense_s)(si_rnn)\n",
    "    si_attn = TimeDistributed(BatchNormalization())(si_attn)\n",
    "\n",
    "    # apply an attention function on Y side by producing an vector of scalars denoting the attention for each token\n",
    "    si_foc = focus(N, qi_aggreg_attn, si_attn, si_rnn, conf['sdim'], adim, conf['l2reg'], pfx=pfx)\n",
    "\n",
    "    si_aggreg, nc_cnn = aggregate(N, conf['pad'], l2reg=conf['l2reg'], cnninit=conf['cnninit'], \n",
    "                                  cnnact=conf['cnnact'], input_dim=nc_rnn, inputs=si_foc, \n",
    "                                  cdim={1: 1/2, 2: 1/2, 3: 1/2, 4: 1/2, 5: 1/2}, pfx='aggre_s'+pfx)\n",
    "    if conf['proj']:\n",
    "        qi_aggreg, si_aggreg = projection_layer([qi_aggreg, si_aggreg], nc_cnn)\n",
    "    \n",
    "    return [qi_aggreg, si_aggreg]\n",
    "\n",
    "def aggregate(pad, dropout=1/2, l2reg=1e-4, cnninit='glorot_uniform', cnnact='relu',\n",
    "        cdim={1: 1/2, 2: 1/2, 3: 1/2, 4: 1/2, 5: 1/2, 6: 1/2, 7: 1/2}, inputs=None, input_dim=304, pfx=''):\n",
    "    cnn_res_list = []\n",
    "    tot_len = 0\n",
    "    for fl, cd in cdim.items():\n",
    "        nb_filter = int(input_dim*cd)\n",
    "        shared_conv = Convolution1D(name=pfx+'conv%d'%(fl), input_shape=(None, conf['pad'], input_dim),\n",
    "                    kernel_size=fl, filters=nb_filter, activation='linear',\n",
    "                    kernel_regularizer=l2(l2reg), kernel_initializer=cnninit)\n",
    "        cnn_res = Activation(cnnact)(BatchNormalization()(shared_conv(inputs)))\n",
    "\n",
    "        pool = MaxPooling1D(pool_size=int(conf['pad']-fl+1), name=pfx+'pool%d'%(fl))\n",
    "        cnn_res = pool(cnn_res)\n",
    "\n",
    "        flatten = Flatten(name=pfx+'flatten%d'%(fl))\n",
    "        cnn_res = flatten(cnn_res)\n",
    "\n",
    "        cnn_res_list.append(cnn_res)\n",
    "\n",
    "        tot_len += nb_filter\n",
    "\n",
    "    aggreg = Dropout(dropout, noise_shape=(tot_len,))(concatenate(cnn_res_list))\n",
    "\n",
    "    return (aggreg, tot_len)\n",
    "\n",
    "def focus(N, input_aggreg, input_seq, orig_seq, sdim, awidth, l2reg, pfx=''):\n",
    "    repeat_vec = RepeatVector(conf['pad'], name='input_aggreg_rep'+pfx)\n",
    "    input_aggreg_rep = repeat_vec(input_aggreg)\n",
    "\n",
    "    attn = Activation('tanh')(add([input_aggreg_rep, input_seq]))\n",
    "\n",
    "    shared_dense = Dense(1, kernel_regularizer=l2(l2reg), name='focus'+pfx)\n",
    "    attn = TimeDistributed(shared_dense)(attn)\n",
    "\n",
    "    flatten = Flatten(name='attn_flatten'+pfx)\n",
    "    attn = flatten(attn)\n",
    "\n",
    "    attn = Activation('softmax')(attn)\n",
    "    attn = RepeatVector(int(N*sdim))(attn)\n",
    "    attn = Permute((2,1))(attn)\n",
    "    output = multiply([orig_seq, attn])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP scoring function\n",
    "To compare two sentence vectors, we used the mlp similarity function.\n",
    "<img src=\"https://github.com/Kyung-Min/CompareModels_TRECQA/blob/master/img/mlp_score.png?raw=true\", style=\"max-width:100%; width: 50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mlp_ptscorer(inputs, Ddim, N, l2reg, pfx='out', oact='sigmoid', extra_inp=[]):\n",
    "    \"\"\" Element-wise features from the pair fed to an MLP. \"\"\"\n",
    "\n",
    "    sum_vec = add(inputs)\n",
    "    mul_vec = multiply(inputs)\n",
    "\n",
    "    mlp_input = concatenate([sum_vec, mul_vec])\n",
    "\n",
    "    # Ddim may be either 0 (no hidden layer), scalar (single hidden layer) or\n",
    "    # list (multiple hidden layers)\n",
    "    if Ddim == 0:\n",
    "        Ddim = []\n",
    "    elif not isinstance(Ddim, list):\n",
    "        Ddim = [Ddim]\n",
    "    if Ddim:\n",
    "        for i, D in enumerate(Ddim):\n",
    "            shared_dense = Dense(int(N*D), kernel_regularizer=l2(l2reg), \n",
    "                                 activation='linear', name=pfx+'hdn%d'%(i))\n",
    "            mlp_input = Activation('tanh')(BatchNormalization()(shared_dense(mlp_input)))\n",
    "\n",
    "    shared_dense = Dense(1, kernel_regularizer=l2(l2reg), activation=oact, name=pfx+'mlp')\n",
    "    mlp_out = shared_dense(mlp_input)\n",
    "    \n",
    "    return mlp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # input embedding         \n",
    "    N, input_nodes_emb, output_nodes_emb = embedding()\n",
    "    \n",
    "    # answer sentence selection\n",
    "    # avg_model / rnn_model / cnn_model / rnncnn_model / attention_model\n",
    "    ptscorer_inputs = avg_model(output_nodes_emb, N, pfx='S')\n",
    "\n",
    "    scoreS = mlp_ptscorer(ptscorer_inputs, conf['Ddim'], N,  \n",
    "            conf['l2reg'], pfx='outS', oact='sigmoid')                \n",
    "\n",
    "    output_nodes = scoreS\n",
    "\n",
    "    model = Model(inputs=input_nodes_emb, outputs=output_nodes)\n",
    "    \n",
    "    model.compile(loss=ranknet, optimizer=conf['opt'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_eval(runid):\n",
    "    print('Model')\n",
    "    model = build_model()\n",
    "    print(model.summary())\n",
    "    \n",
    "    print('Training')\n",
    "    fit_model(model, weightsf='weights-'+runid+'-bestval.h5')\n",
    "    model.save_weights('weights-'+runid+'-final.h5', overwrite=True)\n",
    "    model.load_weights('weights-'+runid+'-bestval.h5')\n",
    "\n",
    "    print('Predict&Eval (best val epoch)')\n",
    "    res = eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, **kwargs):\n",
    "    epochs = conf['epochs']\n",
    "    callbacks = fit_callbacks(kwargs.pop('weightsf'))\n",
    "    \n",
    "    return model.fit(inp_tr, y=y_train, validation_data=[inp_val, y_val], \n",
    "                     callbacks = callbacks, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At every epoch, the callback function measures mrr performance and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_callbacks(weightsf):                                  \n",
    "    return [utils.AnsSelCB(inp_val['q'], inp_val['sents'], y_val, inp_val),\n",
    "            ModelCheckpoint(weightsf, save_best_only=True, monitor='mrr', mode='max'),\n",
    "            EarlyStopping(monitor='mrr', mode='max', patience=conf['patience'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    res = []\n",
    "    for inp in [inp_val, inp_test]:\n",
    "        if inp is None:\n",
    "            res.append(None)\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(inp)\n",
    "        res.append(utils.eval_QA(pred, inp['q'], inp['y'], MAP=False))\n",
    "    return tuple(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainf = 'data/train-all.csv' \n",
    "    valf = 'data/dev.csv'\n",
    "    testf = 'data/test.csv'\n",
    "    params = []\n",
    "    \n",
    "    conf, ps, h = config()\n",
    "\n",
    "    if conf['emb'] == 'Glove': # Please download the GloVe in here http://nlp.stanford.edu/data/glove.6B.zip\n",
    "        print('GloVe')\n",
    "        emb = utils.GloVe(N=conf['embdim'])\n",
    "\n",
    "    print('Dataset')\n",
    "    load_data(trainf,valf,testf)\n",
    "    runid = 'Model-%x' % (h)\n",
    "    print('RunID: %s  (%s)' % (runid, ps))\n",
    "    train_and_eval(runid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
